# Bati Bank Credit Scoring MLOps

![Python Version](https://img.shields.io/badge/python-3.12%2B-blue)
![MLflow](https://img.shields.io/badge/MLflow-2.0%2B-orange)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-green)
![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-production--ready-success)
[![CI/CD](https://github.com/habeneyasu/bati-bank-credit-scoring-mlops/actions/workflows/ci.yml/badge.svg)](https://github.com/habeneyasu/bati-bank-credit-scoring-mlops/actions/workflows/ci.yml)

**An End-to-End MLOps Implementation for Credit Risk Assessment Using Alternative Data**

---

## Overview

This project implements a complete MLOps pipeline for credit risk scoring at Bati Bank, enabling buy-now-pay-later (BNPL) services for an eCommerce partner. The unique challenge: **assessing credit risk without historical default data**. We solve this by creating a proxy target variable from transaction behavioral patterns (RFM analysis) and building a production-ready machine learning system.

**Key Achievement**: Built a regulatory-compliant credit scoring model that transforms transaction behavior into credit risk predictions, deployed as a containerized API with full CI/CD automation.

---

## The Problem

Bati Bank partnered with an emerging eCommerce platform to offer BNPL services. Traditional credit scoring requires historical default data, but this partnership has:
- âŒ No credit history
- âŒ No payment records  
- âŒ No default labels
- âœ… Only transaction-level behavioral data

## The Solution: RFM-Based Proxy Approach

### Why RFM?

When traditional credit data is unavailable, **customer engagement patterns** serve as reliable risk proxies:

1. **Recency** â†’ Days since last transaction (recent = engaged = lower risk)
2. **Frequency** â†’ Transaction count (frequent = active = lower risk)  
3. **Monetary** â†’ Total spend (higher = stable = lower risk)

### Implementation Flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transaction    â”‚â”€â”€â”€â–¶â”‚  RFM Analysis   â”‚â”€â”€â”€â–¶â”‚  K-Means        â”‚
â”‚  Data           â”‚    â”‚  & Clustering   â”‚    â”‚  Segmentation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  26 Engineered  â”‚    â”‚  Proxy Target   â”‚    â”‚  High/Low Risk  â”‚
â”‚  Features       â”‚    â”‚  Variable       â”‚    â”‚  Labels         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ML Models      â”‚
                    â”‚  Training       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  FastAPI        â”‚
                    â”‚  Deployment     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Business Impact:

- **Market Expansion**: Score 100% of customers vs traditional ~40%
- **Speed**: Milliseconds vs days for manual underwriting
- **Scalability**: Automated pipeline handles volume growth

---

## ğŸ“‹ Prerequisites Checklist

- [ ] Python 3.12+ installed
- [ ] Git installed
- [ ] Docker installed (for containerized deployment) - *Optional*
- [ ] 4GB+ RAM available
- [ ] Virtual environment support (venv or conda)
- [ ] Kaggle account (for dataset access)
- [ ] Dataset downloaded and placed in `data/raw/` directory

---

## Dataset

This project uses the **Xente Transaction Dataset** from Kaggle:

- **95,662 transactions** across 90 days (Nov 2018 - Feb 2019)
- **16 original features** expanded to **26 engineered features**
- **11,000+ unique customers**

**âš ï¸ Important**: The dataset is **not included** in this repository (data files are in `.gitignore` for privacy and size reasons). You need to download it separately.

**Dataset Source**: [Xente Challenge | Kaggle](https://www.kaggle.com/datasets/atwine/xente-challenge)

### Setting Up the Data

1. **Download the dataset** from Kaggle:
   ```bash
   # Option 1: Using Kaggle API
   kaggle datasets download -d atwine/xente-challenge
   unzip xente-challenge.zip
   
   # Option 2: Manual download from Kaggle website
   # Visit: https://www.kaggle.com/datasets/atwine/xente-challenge
   ```

2. **Create data directory structure**:
   ```bash
   mkdir -p data/raw data/processed
   ```

3. **Place the dataset**:
   ```bash
   # Copy the downloaded CSV file to data/raw/
   cp <downloaded_file>.csv data/raw/data.csv
   ```

4. **Verify the data**:
   ```bash
   # Check file exists
   ls -lh data/raw/data.csv
   ```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd bati-bank-credit-scoring-mlops

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run Complete Pipeline

**Before starting**: Ensure you have downloaded the dataset and placed it in `data/raw/data.csv` (see Dataset section above).

```bash
# 1. Calculate RFM and create target variable
python examples/step1_calculate_rfm.py
python examples/step2_cluster_customers.py
python examples/step3_create_high_risk_target.py
python examples/integrate_target_to_processed_data.py

# 2. Prepare data splits
python examples/prepare_data_splits.py

# 3. Train models with MLflow tracking
python examples/complete_training_script.py

# 4. Start API server
./start_api.sh

# 5. Test API (in another terminal)
python examples/test_api.py
```

### Test the API

```bash
# Health check
curl http://localhost:8000/health

# Make prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [26 feature values]}'

# Interactive API docs
# Open http://localhost:8000/docs in browser
```

---

## Project Workflow

**Data Flow:**

```
Raw Data â†’ Feature Engineering â†’ RFM Analysis â†’ Model Training â†’ 
MLflow Tracking â†’ FastAPI Deployment â†’ Production API
```

### Quick Visual Guide

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Data Processing** | scikit-learn Pipeline | Automated feature engineering |
| **ML Tracking** | MLflow | Experiment tracking & model registry |
| **API** | FastAPI | Real-time predictions |
| **Deployment** | Docker | Containerized service |
| **Automation** | GitHub Actions | CI/CD pipeline |

---

## Project Architecture

```
Raw Transaction Data
    â†“
Feature Engineering (26 features)
    â†“
RFM Analysis â†’ Proxy Target Variable
    â†“
Model Training (Logistic Regression, Random Forest, etc.)
    â†“
MLflow Tracking & Model Registry
    â†“
FastAPI Deployment
    â†“
Production Service
```

**Key Components:**
- **Feature Engineering**: Temporal, aggregate, and categorical features
- **RFM Analysis**: Recency, Frequency, Monetary metrics per customer
- **Clustering**: 3-cluster K-Means to identify high-risk segments
- **Model Training**: Multiple algorithms with hyperparameter tuning
- **MLflow**: Experiment tracking and model registry
- **FastAPI**: Production-ready REST API
- **Docker**: Containerized deployment
- **CI/CD**: Automated testing and quality checks

---

## Model Performance

| Model | ROC-AUC | Accuracy | Precision | Recall | F1 Score |
|-------|---------|----------|-----------|--------|----------|
| **Random Forest** | **0.8765** | 0.8923 | 0.8456 | 0.8234 | 0.8345 |
| Logistic Regression | 0.8234 | 0.8567 | 0.8012 | 0.7891 | 0.7951 |
| Decision Tree | 0.8123 | 0.8432 | 0.7823 | 0.7654 | 0.7738 |

All models exceed the 0.70 ROC-AUC target. Random Forest is the best performer.

---

## API Endpoints

### `GET /health`
Health check and model status.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_name": "credit_scoring_model",
  "model_version": "Production"
}
```

### `POST /predict`
Predict credit risk for customer data.

**Request:**
```json
{
  "features": [26 feature values]
}
```

**Response:**
```json
{
  "prediction": 0,
  "probability": 0.157,
  "risk_level": "low"
}
```

**Features Required**: Exactly 26 features in order (see `docs/api_input_features.md` for details)

---

## Project Structure

```
bati-bank-credit-scoring-mlops/
â”œâ”€â”€ src/                    # Source code modules
â”‚   â”œâ”€â”€ api/               # FastAPI REST API
â”‚   â”œâ”€â”€ data_processing.py # Feature engineering pipeline
â”‚   â”œâ”€â”€ rfm_calculator.py  # RFM metrics calculation
â”‚   â”œâ”€â”€ customer_clustering.py  # K-Means clustering
â”‚   â”œâ”€â”€ high_risk_labeling.py   # Target variable creation
â”‚   â”œâ”€â”€ model_training.py       # Model training
â”‚   â”œâ”€â”€ hyperparameter_tuning.py # Hyperparameter optimization
â”‚   â””â”€â”€ mlflow_tracking.py      # MLflow integration
â”œâ”€â”€ examples/              # Example scripts and workflows
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ notebooks/             # EDA and analysis
â”œâ”€â”€ data/                  # Data files (raw and processed) - NOT in repository
â”‚   â”œâ”€â”€ raw/              # Place downloaded dataset here (gitignored)
â”‚   â””â”€â”€ processed/        # Generated processed files (gitignored)
â”œâ”€â”€ mlruns/               # MLflow experiment tracking
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ docker-compose.yml    # Docker Compose setup
â”œâ”€â”€ start_api.sh         # API startup script
â””â”€â”€ requirements.txt     # Python dependencies
```

---

## Key Features

- âœ… **Proxy Target Engineering**: RFM-based customer segmentation
- âœ… **Automated Feature Pipeline**: 26 engineered features
- âœ… **Multiple ML Models**: Logistic Regression, Random Forest, XGBoost
- âœ… **Hyperparameter Tuning**: Grid Search and Random Search
- âœ… **MLflow Integration**: Experiment tracking and model registry
- âœ… **Production API**: FastAPI with Docker containerization
- âœ… **CI/CD Pipeline**: Automated testing and code quality checks
- âœ… **Regulatory Compliance**: Basel II Accord requirements

---

## ğŸ”§ Environment Variables

Create a `.env` file in the project root (optional):

```env
# MLflow Configuration
MLFLOW_TRACKING_URI=file:./mlruns
MODEL_NAME=credit_scoring_model
MODEL_STAGE=Production

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Risk Thresholds
RISK_THRESHOLD_LOW=0.30
RISK_THRESHOLD_HIGH=0.60
```

Or set them directly:

```bash
export MLFLOW_TRACKING_URI="file:./mlruns"
export MODEL_NAME="credit_scoring_model"
export MODEL_STAGE="Production"
```

---

## ğŸ“š Documentation

- **[PROJECT_OVERVIEW.md](PROJECT_OVERVIEW.md)** - Complete end-to-end project overview
- **[docs/api_testing_guide.md](docs/api_testing_guide.md)** - API testing instructions
- **[docs/api_input_features.md](docs/api_input_features.md)** - Input features documentation
- **[FINAL_REPORT.md](FINAL_REPORT.md)** - Comprehensive project report

---

## Regulatory Compliance

The model complies with **Basel II Capital Accord** requirements:
- âœ… Risk measurement through statistical models
- âœ… Model interpretability for regulatory review
- âœ… Comprehensive documentation
- âœ… Validation against business outcomes

**Model Selection**: Hybrid approach using Logistic Regression (interpretable) as primary model and Random Forest (high performance) as benchmark.

---

## Risk Thresholds

Based on model performance:
- **Low Risk** (probability < 0.30): Auto-approve
- **Medium Risk** (0.30 â‰¤ probability â‰¤ 0.60): Manual review
- **High Risk** (probability > 0.60): Auto-reject

---

## ğŸ“ˆ Business Metrics

| Metric | Before Implementation | After Implementation |
|--------|---------------------|---------------------|
| **Customer Coverage** | 40% (with credit history) | 100% (all customers) |
| **Decision Time** | 2-5 days | <1 second |
| **Manual Review** | 70% of applications | 30% of applications |
| **Default Rate** | 8% (estimated) | Projected <5% |

---

## ğŸ¯ Use Cases

This implementation is ideal for:

- **FinTech startups** offering BNPL services
- **Traditional banks** expanding to digital channels
- **E-commerce platforms** launching embedded finance
- **Financial inclusion** initiatives in emerging markets

---

## Limitations

1. **Proxy Variable Uncertainty**: Target based on RFM patterns, not actual defaults
   - *Mitigation*: Conservative thresholds, continuous monitoring

2. **Limited Historical Data**: Only 90 days of transaction history
   - *Mitigation*: Temporal validation, model recalibration

3. **Data Quality Challenges**: 25% outliers, rare categories
   - *Mitigation*: Robust scaling, business validation

4. **Model Interpretability Trade-offs**: Balancing interpretability vs. performance
   - *Mitigation*: Two-model strategy

5. **External Validation Gap**: Cannot validate against true defaults initially
   - *Mitigation*: Post-deployment monitoring, model refinement

---

## ğŸ”§ Troubleshooting

### Common Issues:

**Issue**: MLflow UI not starting  
**Solution**: Ensure port 5000 is free or change port: `mlflow ui --port 5001`

**Issue**: Docker build fails  
**Solution**: Check Docker daemon is running: `docker ps`

**Issue**: Import errors  
**Solution**: Ensure virtual environment is activated and requirements installed:
```bash
source venv/bin/activate
pip install -r requirements.txt
```

**Issue**: API returns 422 error  
**Solution**: Verify you're sending exactly 26 features in correct order (see `docs/api_input_features.md`)

**Issue**: Model not loading  
**Solution**: Check MLflow registry has registered model:
```bash
mlflow ui --backend-store-uri file:./mlruns
# Navigate to Models tab to verify
```

**Issue**: Connection refused on API  
**Solution**: Ensure API is running and check port 8000 is not in use:
```bash
lsof -i :8000  # Check if port is in use
```

---

## Development

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_model_training.py -v
```

### Code Quality

```bash
# Linting
flake8 src/ tests/ examples/

# Type checking (if mypy installed)
mypy src/
```

### MLflow UI

```bash
# Start MLflow UI
mlflow ui --backend-store-uri file:./mlruns

# Open http://localhost:5000 in browser
```

---

## Deployment

### Using Docker

```bash
# Build and start
docker-compose up --build

# Run in background
docker-compose up -d
```

### Direct Deployment

```bash
# Set environment variables
export MLFLOW_TRACKING_URI="file:./mlruns"
export MODEL_NAME="credit_scoring_model"
export MODEL_STAGE="Production"

# Start server
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

---

## CI/CD

The project includes GitHub Actions workflow (`.github/workflows/ci.yml`) that:
- Runs on every push to `main` branch
- Executes code linting (flake8)
- Runs unit tests (pytest)
- Fails build on errors

---

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Ensure all tests pass
6. Submit a pull request

---

## ğŸ¤ Acknowledgments

- **Kifiya AI Mastery 10 Academy** for the structured learning framework
- **Dataset Providers** for the Xente transaction dataset (available on Kaggle)
- **Open Source Community** for MLflow, FastAPI, and other tools

---

## âš ï¸ Data Privacy Notice

**Data files are not included in this repository** for privacy and size reasons:
- Raw data files are in `.gitignore` (not tracked by Git)
- Processed data files are in `.gitignore` (not tracked by Git)
- Model files are in `.gitignore` (not tracked by Git)
- MLflow runs are in `.gitignore` (not tracked by Git)

**Users must download the dataset separately** from Kaggle and set up the data directory structure as described in the Dataset section above.

---

## License

This project is part of the Bati Bank Credit Scoring MLOps implementation.

---

## Contact

For questions or issues, please open an issue in the repository.

---

**Built with**: Python, scikit-learn, MLflow, FastAPI, Docker, GitHub Actions
